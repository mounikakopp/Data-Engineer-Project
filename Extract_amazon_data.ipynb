{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JvBZpqRVMAc",
        "outputId": "3abeb1f8-af26-4521-efd2-2a1eaf22285f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=f5a3e643ea4bf3339efe93dee9ae4b812e3b0af3d602f1ea9ed4d35e5461d3e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n"
          ]
        }
      ],
      "source": [
        "#Install beautifulsoop this is used to pass the html code and find details inside it.\n",
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install  request  this is used to send request from our pc to amazon website\n",
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuUzvXw_Vh8r",
        "outputId": "98d29d8e-9273-480f-a369-a04daff820f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZR4er8cVz8I",
        "outputId": "6cbd10e6-2e09-4d9b-d052-feb85c152333"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from bs4 import BeautifulSoup\n",
        " import pandas as pd\n",
        " import requests\n",
        " import numpy as np"
      ],
      "metadata": {
        "id": "14y30-fyV4iN"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to send request from local pc to amazon website and get the html code. For this we need URL (for the particular product we are extracting html code, here we are extracting tv data)\n",
        "URL = \"https://www.amazon.com/s?k=tv+qled+65&crid=3G7585ZN8705J&sprefix=tv+qled+65%2Caps%2C167&ref=nb_sb_noss_1\"\n"
      ],
      "metadata": {
        "id": "rkBPHocfWC1n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# http header(this is for user agent). we got this from 'www.whatismybrowser.com' select 'detect my settings' select 'what is my user agent' we will get the link.\n",
        "HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/118.0', 'Accept-Language':'en-US, en;q=0.5'})"
      ],
      "metadata": {
        "id": "ztQuQCp4YRP6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#http request\n",
        "webpage = requests.get(URL,headers=HEADERS)"
      ],
      "metadata": {
        "id": "IqzxDtVaZSyb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Response 200 is succesful\n",
        "webpage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyvt79xFZigU",
        "outputId": "22bcae55-ab07-4cb0-8986-c1382ed81881"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(webpage.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdreG9eoZluV",
        "outputId": "45f7d6f0-e3db-4147-c436-977a130544ea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Soup object containing all the content , this will convert content into html page.\n",
        "soup=BeautifulSoup(webpage.content,\"html.parser\")"
      ],
      "metadata": {
        "id": "xrMicj96Zy5r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find different links on the page , mostly links are inside the anchor tag. Fetch links as list of tag objects.\n",
        "links = soup.find_all(\"a\",attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})"
      ],
      "metadata": {
        "id": "MxhUlKo0aIUw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to get links from links variable.\n",
        "link = links[0].get('href')"
      ],
      "metadata": {
        "id": "biNF7ZJbbSyY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "productlist = \"https://amazon.com\" + link\n",
        "productlist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W2OiXdCoejpH",
        "outputId": "3f0715d7-5e5e-4d86-b615-9b3ba80b9c21"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://amazon.com/TCL-65Q650G-Accelerator-Streaming-Television/dp/B0C1J5228L/ref=sr_1_1?crid=3G7585ZN8705J&keywords=tv+qled+65&qid=1697223414&sprefix=tv+qled+65%2Caps%2C167&sr=8-1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using above link as new url and sending request\n",
        "webpage1 = requests.get(productlist,headers=HEADERS)"
      ],
      "metadata": {
        "id": "OSDYlGCKhQXB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "webpage1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLzk81lZhoTX",
        "outputId": "66b7a24d-bdf4-4b7e-ff98-952b2115bd3b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newsoup=BeautifulSoup(webpage1.content,\"html.parser\")"
      ],
      "metadata": {
        "id": "UmEMi6zAhytU"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to get product title\n",
        "newsoup.find(\"span\",attrs={\"id\":\"productTitle\"}).text.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "LUrs4VNQfp2i",
        "outputId": "1c4b95bd-96ae-404e-cd86-cfe8475435fc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TCL 65-Inch Q6 QLED 4K Smart TV with Google (65Q650G, 2023 Model) Dolby Vision, Atmos, HDR Pro+, Game Accelerator Enhanced Gaming, Voice Remote, Works Alexa, Streaming UHD Television'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to get price\n",
        "newsoup.find(\"span\",attrs={\"class\":\"a-price-whole\"}).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OCZDYdZIf6aX",
        "outputId": "ee30d6f5-8b24-4435-af2d-ae49c7616d11"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'498.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to get rating\n",
        "newsoup.find(\"span\",attrs={\"class\":\"a-icon-alt\"}).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9h3cM_PJmWB_",
        "outputId": "b14047b9-65c4-4c37-b405-6e40030805b9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.2 out of 5 stars'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract Product Title price and rating for entire URL\n",
        "def get_title(soup):\n",
        "\n",
        "    try:\n",
        "        # Outer Tag Object\n",
        "        title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
        "\n",
        "        # Inner NavigatableString Object\n",
        "        title_value = title.text\n",
        "\n",
        "        # Title as a string value\n",
        "        title_string = title_value.strip()\n",
        "\n",
        "    except AttributeError:\n",
        "        title_string = \"\"\n",
        "\n",
        "    return title_string\n",
        "\n",
        "# Function to extract Product Price\n",
        "def get_price(soup):\n",
        "\n",
        "    try:\n",
        "        price = soup.find(\"span\", attrs={'id':'priceblock_ourprice'}).string.strip()\n",
        "\n",
        "    except AttributeError:\n",
        "\n",
        "        try:\n",
        "            # If there is some deal price\n",
        "            price = soup.find(\"span\", attrs={'id':'priceblock_dealprice'}).string.strip()\n",
        "\n",
        "        except:\n",
        "            price = \"\"\n",
        "\n",
        "    return price\n",
        "\n",
        "# Function to extract Product Rating\n",
        "def get_rating(soup):\n",
        "\n",
        "    try:\n",
        "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
        "\n",
        "    except AttributeError:\n",
        "        try:\n",
        "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
        "        except:\n",
        "            rating = \"\"\n",
        "\n",
        "    return rating\n",
        "\n",
        "# Function to extract Number of User Reviews\n",
        "def get_review_count(soup):\n",
        "    try:\n",
        "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
        "\n",
        "    except AttributeError:\n",
        "        review_count = \"\"\n",
        "\n",
        "    return review_count\n",
        "\n",
        "# Function to extract Availability Status\n",
        "def get_availability(soup):\n",
        "    try:\n",
        "        available = soup.find(\"div\", attrs={'id':'availability'})\n",
        "        available = available.find(\"span\").string.strip()\n",
        "\n",
        "    except AttributeError:\n",
        "        available = \"Not Available\"\n",
        "\n",
        "    return available"
      ],
      "metadata": {
        "id": "K-OcQ0VVmoy0"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    # add your user agent\n",
        "    HEADERS = ({'User-Agent':'', 'Accept-Language': 'en-US, en;q=0.5'})\n",
        "\n",
        "    # The webpage URL\n",
        "    URL = \"https://www.amazon.com/s?k=tv+qled+65&crid=3G7585ZN8705J&sprefix=tv+qled+65%2Caps%2C167&ref=nb_sb_noss_1\"\n",
        "\n",
        "    # HTTP Request\n",
        "    webpage = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "    # Soup Object containing all data\n",
        "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "\n",
        "    # Fetch links as List of Tag Objects\n",
        "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
        "\n",
        "    # Store the links\n",
        "    links_list = []\n",
        "\n",
        "    # Loop for extracting links from Tag Objects\n",
        "    for link in links:\n",
        "            links_list.append(link.get('href'))\n",
        "\n",
        "    d = {\"title\":[], \"price\":[], \"rating\":[], \"reviews\":[],\"availability\":[]}\n",
        "\n",
        "    # Loop for extracting product details from each link\n",
        "    for link in links_list:\n",
        "        new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
        "\n",
        "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
        "\n",
        "        # Function calls to display all necessary product information\n",
        "        d['title'].append(get_title(new_soup))\n",
        "        d['price'].append(get_price(new_soup))\n",
        "        d['rating'].append(get_rating(new_soup))\n",
        "        d['reviews'].append(get_review_count(new_soup))\n",
        "        d['availability'].append(get_availability(new_soup))\n",
        "\n",
        "\n",
        "    amazon_df = pd.DataFrame.from_dict(d)\n",
        "    amazon_df['title'].replace('', np.nan, inplace=True)\n",
        "    amazon_df = amazon_df.dropna(subset=['title'])\n",
        "    amazon_df.to_csv(\"amazon_data.csv\", header=True, index=False)"
      ],
      "metadata": {
        "id": "ZnCgv4lUntVi"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}